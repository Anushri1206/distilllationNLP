{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0ff1b8d-3f3e-4c1f-8c22-5c07f2afed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -U transformers==\"4.49.0\" datasets\n",
    "\n",
    "!pip install numpy\n",
    "!pip install -U accelerate\n",
    "!pip install scikit-learn\n",
    "!pip install peft\n",
    "!pip install bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7bffe-0c78-4965-b98e-c7462fe926c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46fdb18-5507-4c7e-931e-9d3ef8f6b6be",
   "metadata": {},
   "source": [
    "Parent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1629d5-69e7-4432-8655-8adf8291fea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e0b5753a4546f4a3e969b3c7f9abef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/632 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d972c6614f4b4ae890ab0523eb5374ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32cffa75be5241f9bb1dba0be4f0aa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78078c30bb7f4fa4952580ea89b8dd3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d4e1cdcbbf4768bdd69060f93643ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b251c008d494bc4a1c2e35e758d9763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b79e3c231184f019da3d4a1821d8524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at Orkhan/llama-2-7b-absa and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8abdd9fffe74472a919e8bedd318696e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67163d3f30fc4602b4cb8cfc931eeaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c017e2d27cb44ed387203100d7c80a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/434 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9849588871002197}]\n",
      "[{'label': 'LABEL_0', 'score': 0.9930717349052429}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"Orkhan/llama-2-7b-absa\", device=0)\n",
    "print(classifier(\"Company misses earnings â€” shares drop sharply.\"))\n",
    "print(classifier(\"Quarterly profits are bad.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "381a287f-e5af-4160-bf7a-b72688e345b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_model_pipeline(model_name, dataset, task, batch_size=32):\n",
    "    classifier = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=model_name,\n",
    "        device=0 if torch.cuda.is_available() else -1,\n",
    "        batch_size=batch_size,\n",
    "        return_all_scores=False,\n",
    "    )\n",
    "\n",
    "    raw_to_sentiment = {\n",
    "        \"LABEL_1\": \"negative\",\n",
    "        \"LABEL_0\": \"positive\",\n",
    "    }\n",
    "\n",
    "    inverse_label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    for example in dataset:\n",
    "        result = classifier(example[\"text\"])[0]\n",
    "        mapped = raw_to_sentiment.get(result[\"label\"], \"neutral\")\n",
    "        predictions.append(mapped)\n",
    "        true_labels.append(inverse_label_map[example[\"label\"]])\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions, average=\"weighted\")\n",
    "\n",
    "    print(f\"Model: {model_name}, Task: {task}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
    "    return accuracy, f1\n",
    "\n",
    "initial_accuracy, initial_f1 = evaluate_model_pipeline(\"Orkhan/llama-2-7b-absa\", dataset, chosen_task)\n",
    "# Model: Orkhan/llama-2-7b-absa, Task: sentiment_analysis, Accuracy: 0.5507, F1-Score: 0.5061"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd1a154-8425-4bab-85d6-5f97802774ba",
   "metadata": {},
   "source": [
    "Child Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e5add78-a902-400f-a5d6-9413c2b96b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_accuracy, initial_f1 = evaluate_model_pipeline(\"bigscience/bloomz-1b1\", dataset, chosen_task)\n",
    "# Model: bigscience/bloomz-1b1, Task: sentiment_analysis, Accuracy: 0.3304, F1-Score: 0.3406"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28920af3-412d-4763-9282-771712dc2848",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d7cc3-284e-4429-bbdf-901deb0a5eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TEACHER = \"Orkhan/llama-2-7b-absa\"\n",
    "STUDENT = \"bigscience/bloom-1b1\"\n",
    "DATASET = \"zeroshot/twitter-financial-news-sentiment\"\n",
    "OUTPUT_DIR = \"./bloom1b_distilled\"\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 3\n",
    "LR = 5e-5\n",
    "DEVICE = 0 if torch.cuda.is_available() else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1012bbee-3161-4862-bbe6-65cdd45170c2",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddc56671-4130-48e1-bdeb-c8bb06e0e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"zeroshot/twitter-financial-news-sentiment\", split=\"train\")\n",
    "ds = ds.shuffle(42).filter(lambda ex: ex[\"label\"] in (0,1))\n",
    "\n",
    "texts = ds[\"text\"]\n",
    "teacher_labels = ds[\"label\"]\n",
    "\n",
    "augmented_texts, augmented_labels = [], []\n",
    "\n",
    "for text, label in zip(texts, teacher_labels):\n",
    "    paraphrase = explain_pipe(\n",
    "        f\"Paraphrase this sentence without changing sentiment: {text}\",\n",
    "        max_new_tokens=64,\n",
    "        do_sample=False\n",
    "    )[0][\"generated_text\"]\n",
    "\n",
    "    augmented_texts.extend([text, paraphrase])\n",
    "    augmented_labels.extend([label, label])\n",
    "\n",
    "# Tokenize all augmented examples\n",
    "inputs = tokenizer(\n",
    "    augmented_texts,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    max_length=MAX_LEN,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "labels = torch.tensor(augmented_labels)\n",
    "\n",
    "from datasets import Dataset\n",
    "ds = Dataset.from_dict({\n",
    "    \"input_ids\": inputs[\"input_ids\"],\n",
    "    \"attention_mask\": inputs[\"attention_mask\"],\n",
    "    \"labels\": labels,\n",
    "})\n",
    "\n",
    "ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "tokenizer = AutoTokenizer.from_pretrained(TEACHER)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def prep(batch):\n",
    "    toks = tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
    "    toks[\"labels\"] = batch[\"label\"]\n",
    "    return toks\n",
    "\n",
    "ds = ds.map(prep, batched=True)\n",
    "ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "ds = ds.filter(lambda ex: ex[\"label\"] in (0,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4051aad-5cc2-4118-b4ea-d2030ec06188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "teacher = AutoModelForSequenceClassification.from_pretrained(TEACHER).to(\"cpu\")\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    llm_int8_enable_fp32_cpu_offload=True,    \n",
    ")\n",
    "\n",
    "student = AutoModelForSequenceClassification.from_pretrained(\n",
    "    STUDENT,\n",
    "    num_labels=2,\n",
    "    quantization_config=quant_config,\n",
    "        device_map=\"auto\", \n",
    "\n",
    " )\n",
    "student.gradient_checkpointing_enable()\n",
    "\n",
    "\n",
    "student = get_peft_model(\n",
    "    student,\n",
    "    LoraConfig(task_type=TaskType.SEQ_CLS, inference_mode=False, r=16)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fc6c4-5bd3-4d35-bb21-486607094457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_teacher_logits(inputs):\n",
    "    with torch.no_grad():\n",
    "        return teacher(**inputs).logits\n",
    "\n",
    "def loss_fn(stu_logits, tea_logits, labels):\n",
    "    soft = F.kl_div(\n",
    "        F.log_softmax(stu_logits/2, dim=-1),\n",
    "        F.softmax(tea_logits/2, dim=-1),\n",
    "        reduction=\"batchmean\"\n",
    "    ) * (2*2)\n",
    "    hard = F.cross_entropy(stu_logits, labels)\n",
    "    return 0.5 * soft + 0.5 * hard\n",
    "\n",
    "class DistillTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        cpu_inputs = {k: v.detach().to(\"cpu\") for k, v in inputs.items()}\n",
    "        teacher_logits = get_teacher_logits(cpu_inputs).to(model.device)\n",
    "        student_outputs = model(**inputs)\n",
    "        return loss_fn(student_outputs.logits, teacher_logits, labels)\n",
    "\n",
    "trainer = DistillTrainer(\n",
    "    model=student,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=OUTPUT,\n",
    "        per_device_train_batch_size=BATCH,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        learning_rate=LR,\n",
    "        bf16=True,\n",
    "        save_total_limit=1,\n",
    "    ),\n",
    "    train_dataset=ds,\n",
    "    eval_dataset=ds,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(OUTPUT)\n",
    "print(\"Model Saved\", OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3978a392-3db3-4827-b7b6-10efb5a59120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: ./distilled-ultralight, Task: sentiment_analysis, Accuracy: 0.3517, F1-Score: 0.34167\n",
    "\n",
    "initial_accuracy, initial_f1 = evaluate_model_pipeline(\n",
    "    model_name=\"./distilled-ultralight\",  \n",
    "    dataset=dataset,\n",
    "    task=chosen_task,\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1513615e-a6e6-4a8a-9e10-033a5e7db544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
