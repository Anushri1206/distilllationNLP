Financial News Sentiment Distillation ğŸ“Š

This repository contains everything you need to run knowledge distillation from a large â€œteacherâ€ model (Orkhan/llama-2-7b-absa) into a smaller â€œstudentâ€ model (bigscience/bloom-1b1) on the zeroshot/twitter-financial-news-sentiment dataset. All steps â€” data augmentation, tokenization, distillation, and evaluation â€” are fully automated in a single Jupyter notebook.


File	Description
distil.ipynb	Endâ€‘toâ€‘end distillation pipeline (data loading â†’ evaluation)
requirements.txt	Python dependencies
README.md	This documentation
ğŸ“¦ Automatically Loaded Resources


Dataset	zeroshot/twitter-financial-news-sentiment
Teacher Model	Orkhan/llama-2-7b-absa
Student Model	bigscience/bloom-1b1
No manual downloads required â€” the notebook handles everything.

âš™ï¸ Requirements

Python â‰¥ 3.9
Jupyter Notebook or JupyterLab
GPU with â‰¥ 16GB VRAM recommended

Launch Jupyter:
jupyter notebook distil.ipynb
Run all cells in order.
Review results in the final evaluation cell.
